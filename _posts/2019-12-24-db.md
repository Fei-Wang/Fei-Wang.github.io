---
layout:     post
title:      "Real-time Scene Text Detection with Differentiable Binarization（DB）论文笔记"
data: 2019-12-24 11:12:00
permalink:  db.html
categories: 论文笔记
tags: db
excerpt: db论文、代码阅读笔记
mathjax: true
---

* content
{:toc}

## DB论文笔记
### 概述
在OCR领域，由于文本的各种形状，使用语义分割方法变得非常流行。最后将概率图二值化的过程对检测的性能影响非常大，DB针对二值化进行了改进。在精度和速度方面都达到了SOTA。

在MSRA-TD500数据集上，使用ResNet-18的backbone的F1值能达到82.8，帧数达到62帧。

![db](/img/db/DB.png)

### 方法设计
#### pipeline
![pipeline](/img/db/pipeline.png)

#### 网络结构
![architecture](/img/db/architecture.png)

特点：
* 'pred'上采样使用的是转置卷积（Deconvolution）进行上采样
* ResNet18和ResNet50中conv3、conv4、conv5过程中的所有的卷机层都使用的是可调节的可变形卷积（modulated deformable convolutions）

#### 二值化操作
* 标准二值化（Standard Binarization，SB）
   
$$
\begin{aligned}
B_{i,j}=& \begin{cases}
     1& P_{i,j} >=t, \\
     0& \text{otherwise}.
 \end{cases} 
\end{aligned}
$$

* 可微的二值化（Differentiable Binarization，DB）
  
  $$
  B_{i,j} = \frac{1}{1+e^{-k(P_{i,j}-T_{i,j})}}
  $$

二值化图示和微分如下所示：

![binarizaiton](/img/db/binarization.png)

#### 标注生成

![label](/img/db/label.png)

* 和PSENET类似，概率图使用收缩的方式进行生成（Vatti clipping algorithm）：

$$
  D = \frac{A(1-r^2)}{L}, \qquad\text{r是收缩比例，经验上取值为0.4}
$$

* 阈值图离边界越近值越大。具体生成方式根据像素到边界欧式距离计算

* 二值化图使用和概率图同样的gt

#### 损失函数

$$
 L = L_b+\alpha \times L_t + \beta \times L_s \qquad \alpha=10,\beta=5
$$

* $L_s$为概率图Loss，使用的是平衡交叉熵，使用了OHEM机制
* $L_t$为阈值图Loss，使用的是L1 Loss
* $L_b$为二值图Loss，使用的是Dice Loss

ps:这里论文和代码部分不一样，以最新的官方代码为准

#### 后处理
进行二值化处理、findContours、box扩充、box_score过滤等过程。。。

需要注意的是
* 后处理不使用阈值图来进行过滤，直接使用概率图和绝对阈值（可以根据验证集表现进行调节），作者号称不损失精度的前提下可以有效的提高速度
* 扩充的方式和label制作过程中收缩的方式相对，具体计算方法为：

$$
D^{\prime} = \frac{A^{\prime} \times r^{\prime}}{L^{\prime}}, \qquad r^{\prime}\text{经验上取值为1.5}
$$
  
### 实验结果

![result](/img/db/result.png)

跟以前方法对的的结果就是吊打，具体表格不贴出来了，详见论文。

### 局限性
无法处理文本内包含文本的情况

### 参考
* paper地址：[https://arxiv.org/pdf/1911.08947.pdf](https://arxiv.org/pdf/1911.08947.pdf)
* code地址：[https://github.com/MhLiao/DB](https://github.com/MhLiao/DB)