---
layout:     post
title:      "EM算法"
data: 2015-07-28 15:31:38
permalink:  em.html
categories: 机器学习
tags: EM
excerpt: EM算法
mathjax: true
---

* content
{:toc}


## 算法
$\qquad$ 输入：观测变量数据 $Y$，隐变量数据 $Z$，联合分布 $P(Y,Z\|\theta)$，条件分布 $P(Z\|Y,\theta)$；

$\qquad$ 输出：模型参数 $\theta$ .

$\qquad$ (1) 选择参数的初值 $\theta^{(0)}$，开始迭代；

$\qquad$ (2) E 步：记 $\theta^{(i)}$ 为第 $i$ 次迭代参数 $\theta$ 的估计值，在第 $i+1$ 次迭代的 E 步，计算

$$\begin{align}Q(\theta,\theta^{(i)})&=E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}]\\
&=\sum_Z\log P(Y,Z|\theta)P(Z|Y,\theta^{(i)})\end{align}
$$

这里，$P(Z\|Y,\theta^{(i)})$ 是在给定观测数据 $Y$ 和当前的参数估计 $\theta^{(i)}$ 下隐变量数据 $Z$ 的条件概率分布；

$\qquad$ (3) M 步：求使 $Q(\theta,\theta^{(i)})$ 极大化的 $\theta$，确定第 $i+1$ 次迭代的参数的估计值 $\theta^{(i+1)}$

$$\theta^{(i+1)}=\arg\max_\theta Q(\theta,\theta^{(i)})$$

$\qquad$ (4) 重复第 (2) 步和第 (3) 步，直到收敛。

## 几点说明
 1. 参数初值可以任意选择，但 EM 算法对初值敏感
 2.  EM 算法不能保证找到全局最优值
 3. 常用的办法是选择几个不同的初值进行迭代，然后对得到的各个值比较，选择最好的。
