---
layout:     post
title:      "矩阵求导"
data: 2019-06-10 21:25:00
permalink:  matrix.html
categories: math
tags: matrix
excerpt: 矩阵求导在机器学习、深度学习中有着广泛的应用。这里进行机器学习中的常用的矩阵、向量求导方法总结
mathjax: true
---

* content
{:toc}

## 说明
本文大部分内容翻译自[Matrix calculus](https://en.wikipedia.org/wiki/Matrix_calculus)，部分结合自身的理解。

简单来说，矩阵求导就是分别将各元素进行求导，然后将求导的结果写成矩阵的形式（向量为矩阵特殊形式），根据写成的矩阵的排列方式，又分为分子记法和分母记法。

* 分子记法：行数和分子相同的纬度，列数和分母相同的纬度。如列向量对列向量的导数为分子各元素分别对分母各元素的导数，然后将结果排列为矩阵，矩阵的行数为分子的行数，矩阵的列数为分母的行数
* 分母记法：行数和分母相同的纬度，列数和分子相同的纬度。如列向量对列向量的导数为分子各元素分别对分母各元素的导数，然后将结果排列为矩阵，矩阵的行数为分母的行数，矩阵的列数为分子的行数

分子和分母记法参见[Layout conventions](https://en.wikipedia.org/wiki/Matrix_calculus#Layout_conventions)，不同的文章可能使用不同的记法，主要就是相差个转置，本文采用分子记法。

向量和矩阵之间，矩阵和矩阵之间的导数涉及到三维、四维张量，这里暂不考虑这种导数。

## 符号说明
我们使用$M(n,m)$表示包含$n$行$m$列的$n*m$实矩阵的空间，该空间中的一般矩阵用粗体大写字母表示，如$\boldsymbol{A,X,Y}$等，

而若该矩阵属于$M(n,1)$，即列向量，则用粗体小写字母表示，如$\boldsymbol{a,x,y}$等，不做特别说明的话，向量默认为列向量，

特别地，$M(1,1)$空间中的元素为标量，用小些斜体字母表示，如$a,x,y$等。

矩阵的转置：$\boldsymbol{X}^{\mathrm{T}}$，矩阵的迹：$\text{tr}(\boldsymbol{X})$，矩阵的行列式：$\text{det}(\boldsymbol{X})$或$\|\boldsymbol{X}\|$，矩阵的范数：$\|\|\boldsymbol{X}\|\|$。

通常使用字母表的前半部分$(a,b,c,\cdots)$用于表示常量，字母表的后半部分$(x,y,z,\cdots)$表示变量。

## 向量求导
向量可以看作只有一列的矩阵，是矩阵求导的特殊情况

### 向量对标量求导
向量$\boldsymbol{y}=[y_1,y_2,\cdots,y_m]^{\mathrm{T}}$对标量$x$的导数写成如下形式：

$$
\frac{\partial{\boldsymbol{y}}}{\partial{x}} = [\frac{\partial{y_1}}{\partial{x}},\frac{\partial{y_2}}{\partial{x}},\cdots,\frac{\partial{y_m}}{\partial{x}}]^{\mathrm{T}}
$$

即：

$$(\frac{\partial{\boldsymbol{y}}}{\partial{x}})_i = \frac{\partial{y_i}}{\partial{x}}$$

### 标量对向量求导
标量$y$对向量$\boldsymbol{x}^{\textrm{T}}=[x_1,x_2,\cdots,x_n]$对的导数写成如下形式：

$$
\frac{\partial{y}}{\partial{\boldsymbol{x}^\textrm{T}}} = [\frac{\partial{y}}{\partial{x_1}},\frac{\partial{y}}{\partial{x_2}},\cdots,\frac{\partial{y}}{\partial{x_n}}]^{\textrm{T}}
$$

即：

$$(\frac{\partial{y}}{\partial{\boldsymbol{x}^{\textrm{T}}}})_i = \frac{\partial{y}}{\partial{x_i}}$$

### 向量对向量求导
向量$\boldsymbol{y}=[y_1,y_2,\cdots,y_m]^{\mathrm{T}}$对向量$\boldsymbol{x}=[x_1,x_2,\cdots,x_n]^{\mathrm{T}}$对的导数写成如下形式：

$$
\frac{\partial{\boldsymbol{y}}}{\partial{\boldsymbol{x}}} = 

\left[
\begin{matrix}
 \frac{\partial{y_1}}{\partial{x_1}} & \frac{\partial{y_1}}{\partial{x_2}}      & \cdots & \frac{\partial{y_1}}{\partial{x_n}}      \\
 \frac{\partial{y_2}}{\partial{x_1}}     &\frac{\partial{y_2}}{\partial{x_2}}    & \cdots & \frac{\partial{y_2}}{\partial{x_n}}      \\
 \vdots & \vdots & \ddots & \vdots \\
 \frac{\partial{y_m}}{\partial{x_1}}     &\frac{\partial{y_m}}{\partial{x_2}}      & \cdots &\frac{\partial{y_m}}{\partial{x_n}}      \\
\end{matrix}
\right]

$$

为$m*n$维矩阵，也叫做雅可比矩阵。即：

$$(\frac{\partial{\boldsymbol{y}}}{\partial{\boldsymbol{x}}})_{ij} = \frac{\partial{y_i}}{\partial{x_j}}$$

## 矩阵求导
### 矩阵对标量求导
矩阵$\boldsymbol{Y}$对标量$x$的导数定义如下：

$$
\frac{\partial{\boldsymbol{Y}}}{\partial{x}} = 

\left[
\begin{matrix}
 \frac{\partial{y_{11}}}{\partial{x}} & \frac{\partial{y_{12}}}{\partial{x}}      & \cdots & \frac{\partial{y_{1n}}}{\partial{x}}      \\
 \frac{\partial{y_{21}}}{\partial{x}}     &\frac{\partial{y_{22}}}{\partial{x}}    & \cdots & \frac{\partial{y_{2n}}}{\partial{x}}      \\
 \vdots & \vdots & \ddots & \vdots \\
 \frac{\partial{y_{m1}}}{\partial{x}}     &\frac{\partial{y_{m2}}}{\partial{x}}      & \cdots &\frac{\partial{y_{mn}}}{\partial{x}}      \\
\end{matrix}
\right]

$$

即：

$$(\frac{\partial{\boldsymbol{Y}}}{\partial{x}})_{ij} = \frac{\partial{y_{ij}}}{\partial{x}}$$

### 标量对矩阵求导
标量$y$对矩阵$\boldsymbol{X}$的导数定义如下：

$$
\frac{\partial{y}}{\partial{\boldsymbol{X}}} = 

\left[
\begin{matrix}
 \frac{\partial{y}}{\partial{x_{11}}} & \frac{\partial{y}}{\partial{x_{21}}}      & \cdots & \frac{\partial{y}}{\partial{x_{p1}}}      \\
 \frac{\partial{y}}{\partial{x_{12}}}     &\frac{\partial{y}}{\partial{x_{22}}}    & \cdots & \frac{\partial{y}}{\partial{x_{p2}}}      \\
 \vdots & \vdots & \ddots & \vdots \\
 \frac{\partial{y}}{\partial{x_{1q}}}     &\frac{\partial{y}}{\partial{x_{2q}}}      & \cdots &\frac{\partial{y}}{\partial{x_{pq}}}      \\
\end{matrix}
\right]

$$

即：

$$(\frac{\partial{y}}{\partial{\boldsymbol{X}}})_{ij} = \frac{\partial{y}}{\partial{x_{ji}}}$$

## 一些恒等式
由上述的向量、矩阵的导数定义，易知：

$$
\frac{\partial{y^\mathrm{T}}}{\partial{x}} = \frac{\partial{y}}{\partial{x^\mathrm{T}}} = (\frac{\partial{y}}{\partial{x}})^{\mathrm{T}}
$$

其中$x,y$为满足上述定义的标量、向量或矩阵。

在微分、求导过程中，有三条法则非常重要，在矩阵的微分、求导过程中也同样重要。
* 链式法则：如果$y = f(g(x))$，则$y^\prime(x) = f^\prime(g(x))g^\prime(x)$
* 乘积法则：$(fg)^\prime = f^\prime g+fg^\prime$
* 求和法则：$(f+g)^\prime = f^\prime + g^\prime$

求和法则是通用的，由于矩阵乘积不是可交换的，所以乘积法则需要注意顺序。链式法则在矩阵对标量和标量对矩阵求导时不适用（这个情况下，一般使用迹运算）。

引入一些记号，为下面恒等式使用：
* 标量$a,b,c,d,e$为常量，标量$u,v$为$x$、$\boldsymbol{x}$或$\boldsymbol{X}$的函数
* 向量$\boldsymbol{a},\boldsymbol{b},\boldsymbol{c},\boldsymbol{d},\boldsymbol{e}$为常向量，向量$\boldsymbol{u},\boldsymbol{v}$为$x$、$\boldsymbol{x}$或$\boldsymbol{X}$的函数
* 矩阵$\boldsymbol{A},\boldsymbol{B},\boldsymbol{C},\boldsymbol{D},\boldsymbol{E}$为常矩阵，矩阵$\boldsymbol{U},\boldsymbol{V}$为$x$、$\boldsymbol{x}$或$\boldsymbol{X}$的函数